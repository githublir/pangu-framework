---
title: 数据治理之数据分片
tags: [数据分片,读写分离,数据持久化]
sidebar_position: 26
slug: /advanced-guide/data-sharding
---
<head>
  <title>盘古开发框架 | 数据治理之数据持久化 | ShardingSphere-JDBC</title>
  <meta name="keywords" content="盘古开发框架 | 数据治理之数据持久化 | ShardingSphere-JDBC" />
  <meta name="description" content="「盘古开发框架」是完全独立于 Spring Cloud 生态的一套轻量灵活、成熟可靠的工业级分布式微服务开发和治理框架（兼容垂直单体分层架构)。它基于 Apache-2.0 协议开源发布，且是免费的。我们希望不仅是开源的受益者，也能成为开源的贡献者，与开源社区一起「共建共享开源生态」。" />
</head>

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

盘古开发框架集成了数据库中间件 [ShardingSphere](https://shardingsphere.apache.org/index.html) 来提供数据治理相关功能。如：数据分片、读写分离、数据加密等。

## 数据分片概念

随着业务规模不断的扩大，将数据集中存储到单一节点的解决方案，在**性能**、**可用性**和**运维成本**等方面已经难于满足高并发和海量数据系统的场景。从性能方面来说，高并发访问请求使得集中式数据库成为系统的最大瓶颈；从可用性的方面来讲，单一数据节点或简单主从架构，已经越来越难以满足大量互联网 To C 业务对高可用的迫切诉求，数据库的可用性俨然已成为整个系统的关键；从运维成本和风险方面考虑，当一个数据库实例中的数据达到阈值以上，数据备份和恢复的时间成本和风险都将随着数据量的大小而愈发不可控。

因此，通过数据分片将存放在单一库中的数据分散至多个库或表中以达到提升性能、提高可用性和降低运维成本的效果。数据分片的有效手段是对数据库进行分库和分表。分库和分表均可以有效的避免由数据量超过可承受阈值而产生的查询瓶颈，同时也是应对高并发和海量数据系统的有效手段。

### 数据分片类型
数据分片可分为垂直分片和水平分片。

#### 垂直分片
垂直分片是按照业务域将数据库纵向切分为不同的数据库。如电商系统的用户库、订单库、会员库、仓储库、账户库等。垂直拆分可以缩库但无法缩表，即可以减小单节点下数据库数据量，但每个数据表里面的数据量是没有变化的；垂直拆分可以一定程度降低单节点数据库的负载，但是每个数据表的并发压力依旧没变。
 
#### 水平分片
水平分片又称为横向拆分。相对于垂直分片，它不再将数据根据业务逻辑分类，而是通过某个字段（或某几个字段），根据某种规则将数据分散至多个库或多个表中。水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是数据分片的标准解决方案。水平分片从具体实现上又可以分为3种：**只分表**、**只分库**、**分库分表**。如下图所示。

<img width="650"
  src={require('/resources/doc/29-pangu-framework-sharding.png').default}
  alt="数据治理之数据分片" />

### 数据分片后面临的问题
虽然数据分片解决了性能、可用性以及单点备份恢复等问题，但分布式的架构在获得了收益的同时，也引入了新的问题。

- 面对如此散乱的分片之后的数据，应用开发工程师和数据库管理员对数据库的操作变得异常繁重就是其中的重要挑战之一。他们需要明确知道数据从哪写入，从哪读取。
- 数据分片后势必会带来分布式事务的处理。能够优雅的处理好分布式事务，这对开发而言也是一个全新的挑战。（分布式事务处理跨参考：[盘古框架分布式事务最佳实践](/docs/advanced-guide/distributed-transaction)）
- 数据库请求路由至多数据节点的时候，部分SQL支持不完整或性能损耗较大的问题。

### 数据分片的几个原则
- 需综合权衡业务场景、客观估算数据分片性价比，不要盲目分片。数据分片在获得收益的同时，也引入了新的问题。
- 分片参考临界值：一般来讲 MySQL单表记录控制在 1000 万以内、数据库单实例数据大小控制在 1 TB 以内是比较合理的范围。
- 分表不分库仅涉及本地事务，垂直分片和水平分片的分库分表均会带来分布式事务。设计过程应考虑不要人为扩大没必要的分布式事务使用边界。
- 分片键的规划尤为重要，需要结合业务特点来精心设计。
- 以尽量单表查询的原则设计分片逻辑。
- 对于大型应用来说，垂直分片和水平分片一定是联合使用的。但对于一些中小型应用而言，可以只采用水平分片（分库分表或只分表）。

总之，采用什么样的数据架构需要结合**性能诉求**、**可用性**、**运维成本**、**开发成本**、**项目背景**和**业务场景**等方面来做权衡选择。上述仅为一些孤立的参考原则。

### 相关专业术语

- **逻辑表**：相同结构的水平拆分数据库（表）的逻辑名称，是 SQL 中表的逻辑标识。如：t_order 表被拆分为 t_order0 和 t_order1，则 t_order 是逻辑表，并不存放数据，仅用于SQL中的逻辑标识。
- **真实表**：在水平拆分的数据库中真实存在的物理表。如：t_order 表被拆分为 t_order0 和 t_order1，则 t_order0 和 t_order1 是真实表表，存放数据。
- **绑定表**：指分片规则一致的主表和子表。 使用绑定表进行多表关联查询时，必须使用分片键进行关联，否则会出现笛卡尔积关联或跨库关联，从而影响查询效率。 例如：t_order 表和 t_order_item 表，均按照 order_id 分片，并且使用 order_id 进行关联，则此两张表互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将大大提升。可以在配置中配置绑定表关系。
- **广播表**：指所有的分片数据源中都存在的表，表结构及其数据在每个数据库中均完全一致。 适用于数据量不大且需要与海量数据的表进行关联查询的场景，例如：字典表。对广播表的DML操作，会自动路由到所有的数据节点。
- **单表**：指不需要参与分片且所有数据源中唯一存在的表。
- **数据节点**：数据分片的最小单元，由数据源名称和真实表组成。 如：ds0.t_order_0。
- **分片键**：用于将数据库（表）水平拆分的数据库字段。
- **分片策略**：分片键 + 分片算法。
- **分布式主键**：对于分片后的表主键不能使用数据库自身的自增列机制，需要额外引入主键生成策略。ShardingSphere 提供了基于 UUID 和 SNOWFLAKE 的分布式主键生成机制，但不建议使用。最灵活的方式还是自己生成分布式ID传给新增的实体对象。盘古框架使用 MyBatis Plus 的主键生成功能。（同样可选 UUID 主键和 SNOWFLAKE 算法主键）
> 提示：SNOWFLAKE 算法主键能保证递增，但不能保证数字的连续性。如果需要递增且连续的分布式主键，需要自己实现。
- **强制分片路由**：基于 Hint 机制指定了强制分片路由的 SQL 将会无视原有的分片逻辑，直接路由至指定的真实数据节点。

## 读写分离实现原理
实现读写分离大致有 3 种方案。如下图所示。
<img width="800"
  src={require('/resources/doc/27-pangu-framework-readwrite-splitting.png').default}
  alt="虚拟业务场景设计" />

- **数据库代理模式（服务端代理）**  
在数据库和应用系统之间独立部署一个数据库代理中间件，所有的 SQL 请求先发送到这个代理，由它完成 SQL 解析、SQL 路由等必要操作。在这种模式下，路由规则都配置到代理上，读写分离的逻辑对开发人员是透明的。

- **数据源代理模式（客户端代理）**  
通过在应用端引入组件包，代理应用普通数据源。在这种模式下，路由规则配置到应用侧，所有 SQL 请求都通过代理数据源完成 SQL 解析、SQL 路由等必要操作。

- ~~**ORM 框架代理模式（客户端代理）**~~  
通过 ORM 框架（Hibernate、Mybatis 等）的插件、拦截器机制实现。这只能算是特定环境下的一种实现方法，不能作为一套完整的标准化解决方案。故在此不做更多描述。

### 技术方案指标对比
 
|<div style={{width:'120px'}}>技术方案</div>| 可选组件 | <div style={{width:'150px'}}>优点</div> | <div style={{width:'200px'}}>缺点</div>
--- | --- | --- | ---
**数据库代理模式** | ShardingSphere-Proxy <br></br> MyCat | 多语言支持<br></br>独立部署（升级简单）<br></br>对开发完全透明 | 独立部署（增加不稳定因素）<br></br> 运维成本高<br></br>性能损耗高
**数据源代理模式 :kiss: ** | ShardingSphere-JDBC | 集成简单、轻松驾驭<br></br>性能较好 | 嵌入 JAR（升级麻烦）<br></br>日常数据维护麻烦
**~~ORM 框架代理模式~~** | 自研/硬编码 | 硬撸一时爽 | 事后火葬场

:::caution 
盘古开发框架使用 ShardingSphere-JDBC 组件，通过数据源代理的方式实现读写分离功能。
:::

## 编程实战

本实例以一主二从的数据库主从集群为例，来演示如何基于盘古框架开发一个读写分离且支持读负载均衡的范例程序。

### 初始化数据库环境
> 基于一个用户信息表来演示。为了方便查看测试效果，我们分别把三个库中的用户姓名字段的值打上不同的标记。

<Tabs>
<TabItem value="master" label="主库 DDL">

``` jsx
主库 DB：pangu-examples

CREATE TABLE `user` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '流水号',
  `name` varchar(255) NOT NULL COMMENT '姓名',
  `birthday` date DEFAULT NULL COMMENT '生日',
  `age` int(11) DEFAULT NULL COMMENT '年龄',
  `user_type` varchar(255) DEFAULT NULL COMMENT '用户类型',
  `gmt_create` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `gmt_update` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=20 DEFAULT CHARSET=utf8mb4 COMMENT='用户信息表';

INSERT INTO `user` (`id`, `name`, `birthday`, `age`, `user_type`) VALUES (1, 'XC（master）', NULL, 18, '1');
```
</TabItem>
<TabItem value="slave-0" label="从库1 DDL">

```jsx
从库1 DB：pangu-examples-0

CREATE TABLE...（建表脚本同主库）

INSERT INTO `user` (`id`, `name`, `birthday`, `age`, `user_type`) VALUES (1, 'XC（slave-0）', NULL, 18, '1');
```
</TabItem>
<TabItem value="account" label="从库2 DDL">

```jsx
从库2 DB：pangu-examples-1

CREATE TABLE...（建表脚本同主库）

INSERT INTO `user` (`id`, `name`, `birthday`, `age`, `user_type`) VALUES (1, 'XC（slave-1）', NULL, 18, '1');
```
</TabItem>
</Tabs>

### 安装相关盘古模块

<Tabs defaultValue="dependency3">
<TabItem value="parent" label="盘古 Parent">

```jsx
<parent>
	<groupId>com.gitee.pulanos.pangu</groupId>
	<artifactId>pangu-parent</artifactId>
	<version>latest.version.xxx</version>
	<relativePath/>
</parent>
```
</TabItem>
<TabItem value="dependency1" label="基础模块">

```jsx
<dependency>
    <groupId>com.gitee.pulanos.pangu</groupId>
    <artifactId>pangu-spring-boot-starter</artifactId>
</dependency>
```
</TabItem>
<TabItem value="dependency2" label="JDBC 模块">

```jsx
<dependency>
	<groupId>com.gitee.pulanos.pangu</groupId>
	<artifactId>pangu-jdbc-spring-boot-starter</artifactId>
</dependency>
```
</TabItem>

<TabItem value="dependency3" label="ShardingSphere 模块">

```jsx
<dependency>
    <groupId>com.gitee.pulanos.pangu</groupId>
    <artifactId>pangu-shardingsphere-spring-boot-starter</artifactId>
</dependency>
```
</TabItem>
</Tabs>

### 本地配置

> 为便于理解，本文基于本地配置的方式编写。若改为标准的 Nacos 配置中心模式，请参阅：[配置中心](/docs/advanced-guide/nacos-config-center)章节。

<Tabs>
<TabItem value="application" label="application.properties">

```jsx
spring.profiles.active=${spring.profiles.active:dev}
```
</TabItem>
<TabItem value="application-dev" label="application-dev.properties">

```jsx
spring.application.name=pangu-examples-shardingsphere-readwrite-splitting

mybatis-plus.mapperLocations=classpath*:/mapper/**/*.xml
mybatis-plus.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl

spring.shardingsphere.datasource.names=ds-master,ds-slave-0,ds-slave-1

# 主库数据源配置
spring.shardingsphere.datasource.ds-master.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds-master.driver-class-name=com.mysql.cj.jdbc.Driver
spring.shardingsphere.datasource.ds-master.jdbc-url=jdbc:mysql://localhost:3306/pangu-examples
spring.shardingsphere.datasource.ds-master.username=root
spring.shardingsphere.datasource.ds-master.password=root123456

# 从库1数据源配置
spring.shardingsphere.datasource.ds-slave-0.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds-slave-0.driver-class-name=com.mysql.cj.jdbc.Driver
spring.shardingsphere.datasource.ds-slave-0.jdbc-url=jdbc:mysql://localhost:3306/pangu-examples-0
spring.shardingsphere.datasource.ds-slave-0.username=root
spring.shardingsphere.datasource.ds-slave-0.password=root123456

# 从库2数据源配置
spring.shardingsphere.datasource.ds-slave-1.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds-slave-1.driver-class-name=com.mysql.cj.jdbc.Driver
spring.shardingsphere.datasource.ds-slave-1.jdbc-url=jdbc:mysql://localhost:3306/pangu-examples-1
spring.shardingsphere.datasource.ds-slave-1.username=root
spring.shardingsphere.datasource.ds-slave-1.password=root123456

# 读写分离策略配置
spring.shardingsphere.rules.readwrite-splitting.data-sources.pangu-rws.type=Static
# 写数据源配置
spring.shardingsphere.rules.readwrite-splitting.data-sources.pangu-rws.props.write-data-source-name=ds-master
# 读数据源配置
spring.shardingsphere.rules.readwrite-splitting.data-sources.pangu-rws.props.read-data-source-names=ds-slave-0,ds-slave-1
# 读负载均衡算法配置
spring.shardingsphere.rules.readwrite-splitting.load-balancers.read-random.type=RANDOM


logging.level.root=INFO
logging.level.com.gitee.pulanos.pangu=INFO
```
</TabItem>
</Tabs>

### 主要逻辑代码

#### 读操作自动走从库负载均衡
```jsx
public void readRoute() {
	log.info("查询数据...");
	UserEntity userEntity = userMapper.selectById(1L);
	log.info("查询结果 {}", userEntity);
}
```

#### 读操作强制走主库
```jsx
public void readByWriteRoute() {
	HintManager hintManager = HintManager.getInstance();
	hintManager.setWriteRouteOnly();
	try {
		log.info("查询数据（强制走主库）...");
		UserEntity userEntity = userMapper.selectById(1L);
		log.info("查询结果 {}", userEntity);
	} finally {
		hintManager.close();
	}
}
```

#### 写操作自动走主库
```jsx
public int writeRoute() {
	log.info("插入数据...");
	UserEntity userEntity = new UserEntity();
	userEntity.setName("XC").setAge(18).setUserType("1");
	int row = userMapper.insert(userEntity);
	log.info("成功插入{}条数据。{}", row, userEntity);
	return row;
}
```

#### 事务方法里的所有读写操作都自动走主库
```jsx
@Transactional(rollbackFor = RuntimeException.class)
public void doWithTransaction() {
	log.info("插入数据...");
	UserEntity userEntity = new UserEntity();
	userEntity.setName("XC").setAge(18).setUserType("1");
	int row = userMapper.insert(userEntity);
	log.info("成功插入{}条数据。{}", row, userEntity);
	log.info("查询数据（强制走主库）...");
	UserEntity userEntityRead = userMapper.selectById(1L);
	log.info("查询结果 {}", userEntityRead);
}
```

## 测试

### 启动类
```jsx
@EnableTransactionManagement
@SpringBootApplication
public class ReadWriteSplittingApplication {
	public static void main(String[] args) {
		PanGuApplicationBuilder.init(ReadWriteSplittingApplication.class).run(args);
	}
}
```

### 测试用例

#### 测试读操作自动走从库负载均衡
```jsx
@Test
public void readRoute() {
	readWriteSplittingService.readRoute();
	readWriteSplittingService.readRoute();
}
```

#### 测试读操作强制走主库
```jsx
@Test
public void readByWriteRoute() {
	readWriteSplittingService.readByWriteRoute();
}
```

#### 测试写操作自动走主库
```jsx
@Test
public void writeRoute() {
	readWriteSplittingService.writeRoute();
}
```

#### 测试事务方法里的所有读写操作都自动走主库
```jsx
@Test
public void doWithTransaction() {
	readWriteSplittingService.doWithTransaction();
}
```

## 本文相关范例源码
- [pangu-examples-shardingsphere-readwrite-splitting](https://gitee.com/pulanos/pangu-framework/tree/master/pangu-examples/pangu-examples-shardingsphere-readwrite-splitting)：数据治理之读写分离范例

## 下一步
继续阅读其它章节获取你想要的答案或通过我们的 [开发者社区](/docs/community) 寻求更多帮助。

